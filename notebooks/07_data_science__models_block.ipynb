{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjCcI8+dQlg4hujpmUIune",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rvkushnir/project_fifa_players/blob/main/notebooks/07_data_science__models_block.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ініціалізація середовища**\n",
        "\n",
        "Клонуємо репозиторій з GitHub у /content, переходимо в корінь проєкту.\n",
        "Це гарантує однакові шляхи для даних/виводів у всіх сесіях Colab.\n",
        "Після клонування перевіряємо наявність data/raw/fifa_players.csv.\n",
        "Вихід: робочий каталог → pwd = /content/project_fifa_players."
      ],
      "metadata": {
        "id": "2GtEVJUFLyHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Ініціалізація середовища: клон репозиторію і перехід у робочу теку\n",
        "REPO = \"rvkushnir/project_fifa_players\"\n",
        "BRANCH = \"main\"\n",
        "WORKDIR = \"/content/project_fifa_players\"\n",
        "\n",
        "# чистий клон\n",
        "!rm -rf \"$WORKDIR\"\n",
        "!git clone --depth 1 -b \"$BRANCH\" \"https://github.com/{REPO}.git\" \"$WORKDIR\"\n",
        "%cd \"$WORKDIR\"\n",
        "\n",
        "# Якщо у репо використовується Git LFS (великі файли) — підтягнемо дані\n",
        "!git lfs install 2>/dev/null || true\n",
        "!git lfs pull 2>/dev/null || true\n",
        "\n",
        "# Перевіримо, що CSV на місці\n",
        "!ls -lah data/raw\n"
      ],
      "metadata": {
        "id": "eIldSeZVLyYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task20 — класифікація позиції гравця (set-based оцінювання)\n",
        "\n",
        "Що прогнозуємо. Для кожного гравця є множина реальних позицій (з player_positions). Ми оцінюємо моделі за тим, чи потрапляє передбачена позиція в цю множину. Поле primary_position використовується лише як технічна single-label проксі для тренування частини моделей і діагностики; у метриках воно не має пріоритету.\n",
        "\n",
        "Фічсети (дві стратегії)\n",
        "\n",
        "A-48 (фіксований) — компактний, інтерпретований набір із 48 ознак:\n",
        "базовий профіль (overall, potential, антропометрія, репутація, нога тощо) + 7 інтегральних індексів (pace_idx, dribble_idx, …, gk_idx) + помірний пул технічних ознак, добраний детерміновано (добираємо детальні скіли з найбільшою |corr| з overall як проксі якості) до рівно 48 фіч.\n",
        "Перевага: стабільний і “легкий”; мета: сильна база без складного відбору.\n",
        "\n",
        "B-42 (автовідбір) — 42 найінформативніші фічі з великого детального пулу (див. Task19).\n",
        "Як відбирали (у Task19):\n",
        "\n",
        "mutual_info_classif (агрегація важливості категорій назад на “сиру” фічу через максимум по one-hot стовпцях);\n",
        "\n",
        "RandomForest importance, усереднена по 5-фолдовому CV (знову згортаємо важливості one-hot → сирі фічі);\n",
        "\n",
        "комбінований рейтинг rank_sum = rank_MI + rank_RF;\n",
        "\n",
        "анти-колінеарність: drop надлишково корельованих числових фіч (|r| ≥ 0.95);\n",
        "\n",
        "беремо top-K = 42 → Task19_selected_features_B.csv.\n",
        "Перевага: максимально інформативний під реальні дані.\n",
        "\n",
        "Сценарії даних\n",
        "\n",
        "no_leak — чисті ознаки.\n",
        "\n",
        "with_leak — додаємо з RAW club_position/nation_position (оцінюємо вплив потенційного “витоку” доменної інформації).\n",
        "\n",
        "Моделі\n",
        "\n",
        "Плоскі (flat):\n",
        "\n",
        "LR — LogisticRegression(lbfgs, C=1.5, max_iter=6000); сильна лінійна база, добре працює з OHE.\n",
        "\n",
        "RF — RandomForest(n_estimators=600, min_samples_leaf=2); робастний до шуму, дає ймовірності.\n",
        "\n",
        "HGB — HistGradientBoostingClassifier як швидкий сучасний бустинг.\n",
        "\n",
        "XGB* — XGBClassifier(max_depth=6, lr=0.10, n_estimators≈650, subsample=0.8, colsample_bytree=0.8, tree_method=\"hist\").\n",
        "Якщо XGBoost недоступний, автоматично використовуємо HGB як фолбек.\n",
        "\n",
        "Ієрархічні (group → position):\n",
        "\n",
        "1. Класифікатор групи (GK/DEF/MID/FWD): P(g|x).\n",
        "\n",
        "2. Усередині кожної групи — свій класифікатор позиції: P(pos|x, g).\n",
        "\n",
        "3. Підсумок: P(pos∣x)=∑gP(g∣x)⋅P(pos∣x,g).\n",
        "Навіщо: використовує природну таксономію позицій, зменшує плутанину між далекими класами.\n",
        "\n",
        "Ансамблі (soft-vote):\n",
        "\n",
        "Середнє по ймовірностях кількох flat-моделей (LR+HGB; LR+HGB+XGB).\n",
        "\n",
        "Перед усередненням вирівнюємо порядок класів.\n",
        "\n",
        "Калібрування ймовірностей: для дерев/бустингів — CalibratedClassifierCV(method=\"isotonic\", cv=3) для кращого top-k.\n",
        "\n",
        "Препроцесинг і CV\n",
        "\n",
        "ColumnTransformer:\n",
        "— числові → StandardScaler(with_mean=False);\n",
        "— категоріальні → OneHotEncoder(handle_unknown=\"ignore\").\n",
        "\n",
        "5-фолдова StratifiedKFold за primary_position (стабільні класи у фолдах).\n",
        "\n",
        "Фіксуємо сид: SEED=42.\n",
        "\n",
        "Для XGB кодуємо цілі LabelEncoder з фіксованим простором міток.\n",
        "\n",
        "Метрики (основний фокус — множини позицій)\n",
        "\n",
        "acc_any — частка кейсів, де передбачена позиція ∈ множині реальних позицій гравця.\n",
        "\n",
        "top2_any — хіт, якщо хоч одна з топ-2 передбачених позицій входить до множини реальних.\n",
        "\n",
        "avg_cost_any — середній штраф: 0 якщо вгадали; 1 якщо промах, але група (DEF/MID/FWD/GK) збіглась з групою бодай однієї реальною позицією; 3 якщо промах і група інша.\n",
        "\n",
        "Діагностика (single-label proxy): macro_f1, balanced_acc — лише щоб бачити, чи класифікатор у принципі “адекватний”; у висновках не використовуємо.\n",
        "\n",
        "Метрики acc_primary та top2_acc вилучені — у задачі немає “головної” позиції; важливо влучити будь-яку реальну позицію.\n",
        "\n",
        "Вивід\n",
        "\n",
        "Детальні фолдові результати → out/tables/Task20_FULL_runs_detailed.csv.\n",
        "\n",
        "Зведена таблиця (усереднено по фолдах) → out/tables/Task20_FULL_results_summary.csv.\n",
        "\n",
        "Порівнюємо фічсети (A-48 vs B-42) і сценарії (no_leak vs with_leak) для кожного типу моделі."
      ],
      "metadata": {
        "id": "Pn8t94sLNE0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Task20_FULL: All models (flat/hier/ensembles) on A-48 and B-42, leak/no_leak — set-based metrics only\n",
        "from pathlib import Path\n",
        "import warnings, numpy as np, pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import f1_score, balanced_accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "\n",
        "SEED      = 42\n",
        "N_SPLITS  = 5\n",
        "CALIBRATE = True\n",
        "RAW_CSV   = Path(\"data/raw/fifa_players.csv\")\n",
        "IN_FE     = Path(\"out/tables/Task18_features_train.csv\")\n",
        "SEL_B42   = Path(\"out/tables/Task19_selected_features_B.csv\")  # B-42 з блоку 6\n",
        "OUT_DIR   = Path(\"out/tables\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "#  Data\n",
        "df = pd.read_csv(IN_FE, low_memory=False)\n",
        "POS = df[\"primary_position\"].astype(str)  # single-label proxy лише для тренування/діагностики\n",
        "\n",
        "# Groups\n",
        "DEF = {\"CB\",\"LB\",\"RB\",\"LWB\",\"RWB\"}\n",
        "MID = {\"CDM\",\"CM\",\"CAM\",\"LM\",\"RM\"}\n",
        "FWD = {\"ST\",\"CF\",\"LW\",\"RW\"}\n",
        "GMAP = {\n",
        "    \"GK\":\"GK\",\n",
        "    \"CB\":\"DEF\",\"LB\":\"DEF\",\"RB\":\"DEF\",\"LWB\":\"DEF\",\"RWB\":\"DEF\",\n",
        "    \"CDM\":\"MID\",\"CM\":\"MID\",\"CAM\":\"MID\",\"LM\":\"MID\",\"RM\":\"MID\",\n",
        "    \"LW\":\"FWD\",\"RW\":\"FWD\",\"ST\":\"FWD\",\"CF\":\"FWD\"\n",
        "}\n",
        "def to_grp(p):\n",
        "    p=str(p).upper()\n",
        "    if p==\"GK\": return \"GK\"\n",
        "    if p in DEF: return \"DEF\"\n",
        "    if p in MID: return \"MID\"\n",
        "    if p in FWD: return \"FWD\"\n",
        "    return \"OTHER\"\n",
        "\n",
        "# Для ієрархічної моделі потрібні групи на train-проксі\n",
        "GRP = (df[\"role_group\"].astype(str) if \"role_group\" in df.columns\n",
        "       else df[\"primary_position\"].astype(str).map(to_grp))\n",
        "\n",
        "# LabelEncoder для XGB\n",
        "LE_POS = LabelEncoder().fit(POS)\n",
        "\n",
        "# match-any sets (істина)\n",
        "assert RAW_CSV.exists(), \"Немає RAW CSV: data/raw/fifa_players.csv\"\n",
        "raw_pos = (pd.read_csv(RAW_CSV, usecols=[\"sofifa_id\",\"player_positions\"])\n",
        "             .drop_duplicates(\"sofifa_id\"))\n",
        "CANON15 = {\"GK\",\"CB\",\"LB\",\"RB\",\"LWB\",\"RWB\",\"CDM\",\"CM\",\"CAM\",\"LM\",\"RM\",\"LW\",\"RW\",\"ST\",\"CF\"}\n",
        "def parse_positions_list(s: str) -> list[str]:\n",
        "    if pd.isna(s): return []\n",
        "    return [t.strip().upper() for t in str(s).split(\",\") if t.strip() and t.strip().upper() in CANON15]\n",
        "pos_sets_map = {\n",
        "    int(r.sofifa_id): parse_positions_list(r.player_positions)\n",
        "    for r in raw_pos.itertuples(index=False)\n",
        "}\n",
        "\n",
        "#  Feature variants\n",
        "# B-42 — з файлу\n",
        "sel_B = pd.read_csv(SEL_B42)[\"feature\"].tolist()\n",
        "if len(sel_B) > 42: sel_B = sel_B[:42]\n",
        "\n",
        "# A-48 — фіксований компактний набір (48 ознак)\n",
        "def build_A48_alt(dfref) -> list:\n",
        "    must_keep_front = [\n",
        "        \"overall\",\"potential\",\"age\",\"height_cm\",\"weight_kg\",\n",
        "        \"weak_foot\",\"skill_moves\",\"international_reputation\",\n",
        "        \"pace_idx\",\"dribble_idx\",\"playmake_idx\",\"attack_idx\",\"defend_idx\",\"phys_idx\",\"gk_idx\",\n",
        "        \"work_rate\",\"preferred_foot\",\"body_type\",\"work_att\",\"work_def\"\n",
        "    ]\n",
        "    cols = [c for c in must_keep_front if c in dfref.columns]\n",
        "    # добираємо з технічних\n",
        "    patterns = (\"attacking_\",\"skill_\",\"movement_\",\"mentality_\",\"power_\",\"defending_\",\"goalkeeping_\")\n",
        "    detail = [c for c in dfref.columns if c.startswith(patterns)]\n",
        "    num_detail = [c for c in detail if pd.api.types.is_numeric_dtype(dfref[c])]\n",
        "    corr = dfref[num_detail].corrwith(dfref[\"overall\"]).abs().sort_values(ascending=False)\n",
        "    tail = [c for c in corr.index if c not in cols]\n",
        "    for c in tail:\n",
        "        if len(cols) >= 48: break\n",
        "        cols.append(c)\n",
        "    return cols[:48]\n",
        "\n",
        "sel_A = build_A48_alt(df)\n",
        "\n",
        "VARIANTS = {\n",
        "    \"B42\": sel_B,\n",
        "    \"A48\": sel_A\n",
        "}\n",
        "\n",
        "# ----------------------- Utils -----------------------\n",
        "def OHE_dense():\n",
        "    try:\n",
        "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "    except TypeError:\n",
        "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
        "\n",
        "def make_preprocessor(X_cols, dfref):\n",
        "    num_cols = [c for c in X_cols if pd.api.types.is_numeric_dtype(dfref[c])]\n",
        "    cat_cols = [c for c in X_cols if not pd.api.types.is_numeric_dtype(dfref[c])]\n",
        "    return ColumnTransformer([\n",
        "        (\"num\", StandardScaler(with_mean=False), num_cols),\n",
        "        (\"cat\", OHE_dense(), cat_cols)\n",
        "    ], remainder=\"drop\")\n",
        "\n",
        "def maybe_calibrate(est):\n",
        "    if not CALIBRATE:\n",
        "        return est\n",
        "    name = est.__class__.__name__.lower()\n",
        "    if any(x in name for x in [\"histgradientboosting\",\"randomforest\",\"xgb\"]):\n",
        "        return CalibratedClassifierCV(estimator=est, method=\"isotonic\", cv=3)\n",
        "    return est\n",
        "\n",
        "def with_leak_df(df_in: pd.DataFrame, want_leak: bool):\n",
        "    if not want_leak:\n",
        "        return df_in.copy(), []\n",
        "    if \"sofifa_id\" in df_in.columns and RAW_CSV.exists():\n",
        "        raw = pd.read_csv(RAW_CSV, usecols=[\"sofifa_id\",\"club_position\",\"nation_position\"]) \\\n",
        "                .drop_duplicates(\"sofifa_id\").set_index(\"sofifa_id\")\n",
        "        df2 = df_in.copy()\n",
        "        for c in [\"club_position\",\"nation_position\"]:\n",
        "            if c in raw.columns:\n",
        "                df2[c] = df2[\"sofifa_id\"].map(raw[c])\n",
        "        leak_cols = [c for c in [\"club_position\",\"nation_position\"] if c in df2.columns]\n",
        "        return df2, leak_cols\n",
        "    return df_in.copy(), []\n",
        "\n",
        "# ---- set-based метрики ----\n",
        "def acc_any_from_sets(yhat: np.ndarray, ids: np.ndarray) -> float:\n",
        "    hits = []\n",
        "    for i, p in enumerate(yhat):\n",
        "        truths = set(pos_sets_map.get(int(ids[i]), []))\n",
        "        hits.append(p in truths)\n",
        "    return float(np.mean(hits)) if len(hits) else 0.0\n",
        "\n",
        "def topk_acc_any(proba: np.ndarray, ids: np.ndarray, classes: np.ndarray, k: int = 2) -> float:\n",
        "    topk_idx = np.argsort(proba, axis=1)[:, ::-1][:, :k]\n",
        "    clmap = {i: c for i, c in enumerate(classes)}\n",
        "    hits = []\n",
        "    for i, row in enumerate(topk_idx):\n",
        "        preds = {clmap[j] for j in row}\n",
        "        truths = set(pos_sets_map.get(int(ids[i]), []))\n",
        "        hits.append(len(preds & truths) > 0)\n",
        "    return float(np.mean(hits)) if len(hits) else 0.0\n",
        "\n",
        "def group_acc_any(yhat: np.ndarray, ids: np.ndarray) -> float:\n",
        "    hits = []\n",
        "    for i, p in enumerate(yhat):\n",
        "        pred_g = GMAP.get(p, \"OTHER\")\n",
        "        truths = set(pos_sets_map.get(int(ids[i]), []))\n",
        "        true_g = {GMAP.get(t, \"OTHER\") for t in truths}\n",
        "        hits.append(pred_g in true_g if true_g else False)\n",
        "    return float(np.mean(hits)) if len(hits) else 0.0\n",
        "\n",
        "COST = {\"intra\": 1.0, \"cross\": 3.0}\n",
        "def avg_cost_any_from_sets(yhat: np.ndarray, ids: np.ndarray) -> float:\n",
        "    costs = []\n",
        "    for i, p in enumerate(yhat):\n",
        "        truths = set(pos_sets_map.get(int(ids[i]), []))\n",
        "        if not truths:\n",
        "            costs.append(COST[\"cross\"]); continue\n",
        "        if p in truths:\n",
        "            costs.append(0.0); continue\n",
        "        pred_g = GMAP.get(p, \"OTHER\")\n",
        "        true_g = {GMAP.get(t, \"OTHER\") for t in truths}\n",
        "        costs.append(COST[\"intra\"] if pred_g in true_g else COST[\"cross\"])\n",
        "    return float(np.mean(costs)) if len(costs) else 0.0\n",
        "\n",
        "# unify proba to a given class order\n",
        "def align_proba(P, src_classes, tgt_classes):\n",
        "    idx = {c:i for i,c in enumerate(src_classes)}\n",
        "    aligned = np.zeros((P.shape[0], len(tgt_classes)), dtype=float)\n",
        "    for j, c in enumerate(tgt_classes):\n",
        "        if c in idx:\n",
        "            aligned[:, j] = P[:, idx[c]]\n",
        "    return aligned\n",
        "\n",
        "# ----------------------- Estimators -----------------------\n",
        "USE_XGB = True\n",
        "def make_flat_estimator(key):\n",
        "    key = key.lower()\n",
        "    if key == \"flat_lr\":\n",
        "        return LogisticRegression(C=1.5, max_iter=6000, solver=\"lbfgs\", n_jobs=-1, random_state=SEED)\n",
        "    if key == \"flat_rf\":\n",
        "        return RandomForestClassifier(n_estimators=600, min_samples_leaf=2, n_jobs=-1, random_state=SEED)\n",
        "    if key in [\"flat_hgb\", \"flat_xgb\"]:\n",
        "        if key == \"flat_xgb\" and USE_XGB:\n",
        "            try:\n",
        "                from xgboost import XGBClassifier\n",
        "                return XGBClassifier(\n",
        "                    objective=\"multi:softprob\", eval_metric=\"mlogloss\",\n",
        "                    max_depth=6, learning_rate=0.10, n_estimators=650,\n",
        "                    subsample=0.8, colsample_bytree=0.8,\n",
        "                    tree_method=\"hist\", n_jobs=-1, random_state=SEED\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(\"[WARN] xgboost недоступний — фолбек на HGB:\", e)\n",
        "        return HistGradientBoostingClassifier(random_state=SEED)\n",
        "    raise ValueError(f\"Unknown model key: {key}\")\n",
        "\n",
        "def make_group_estimator():\n",
        "    return HistGradientBoostingClassifier(random_state=SEED)\n",
        "\n",
        "def make_pos_estimator(kind, n_classes):\n",
        "    if n_classes <= 1:\n",
        "        return None\n",
        "    if kind == \"xgb\" and USE_XGB:\n",
        "        try:\n",
        "            from xgboost import XGBClassifier\n",
        "            obj = \"binary:logistic\" if n_classes == 2 else \"multi:softprob\"\n",
        "            evalm = \"logloss\" if n_classes == 2 else \"mlogloss\"\n",
        "            return XGBClassifier(\n",
        "                objective=obj, eval_metric=evalm,\n",
        "                max_depth=6, learning_rate=0.10, n_estimators=500,\n",
        "                subsample=0.8, colsample_bytree=0.8,\n",
        "                tree_method=\"hist\", n_jobs=-1, random_state=SEED\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] xgboost недоступний — фолбек на HGB:\", e)\n",
        "    return HistGradientBoostingClassifier(random_state=SEED)\n",
        "\n",
        "# ----------------------- Runners -----------------------\n",
        "def run_flat(model_key, df_use, X_cols, scenario):\n",
        "    rows = []\n",
        "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "    for fold, (tr, te) in enumerate(skf.split(df_use[X_cols], POS), 1):\n",
        "        Xtr, Xte = df_use.iloc[tr][X_cols], df_use.iloc[te][X_cols]\n",
        "        ytr, yte = POS.iloc[tr], POS.iloc[te]  # proxy лише для тренування/діагностики\n",
        "        ids_te = df_use.iloc[te][\"sofifa_id\"].astype(int).values\n",
        "\n",
        "        pre = make_preprocessor(X_cols, df_use)\n",
        "        est = make_flat_estimator(model_key)\n",
        "\n",
        "        use_le = (model_key == \"flat_xgb\" and hasattr(est, \"fit\") and est.__class__.__name__.lower().startswith(\"xgb\"))\n",
        "        est_c = maybe_calibrate(est)\n",
        "        pipe = Pipeline([(\"prep\", pre), (\"clf\", est_c)])\n",
        "\n",
        "        if use_le:\n",
        "            pipe.fit(Xtr, LE_POS.transform(ytr))\n",
        "            proba = pipe.predict_proba(Xte)\n",
        "            classes_lbl = LE_POS.inverse_transform(pipe.named_steps[\"clf\"].classes_) \\\n",
        "                          if hasattr(pipe.named_steps[\"clf\"], \"classes_\") else np.sort(POS.unique())\n",
        "            yhat = classes_lbl[proba.argmax(axis=1)]\n",
        "        else:\n",
        "            pipe.fit(Xtr, ytr)\n",
        "            proba = pipe.predict_proba(Xte)\n",
        "            classes_lbl = pipe.named_steps[\"clf\"].classes_\n",
        "            yhat  = classes_lbl[proba.argmax(axis=1)]\n",
        "\n",
        "        # метрики (усі set-based, крім діагностичних нижче)\n",
        "        acc_a  = acc_any_from_sets(yhat, ids_te)\n",
        "        t2a    = topk_acc_any(proba, ids_te, classes_lbl, k=2)\n",
        "        gacc   = group_acc_any(yhat, ids_te)\n",
        "        cost_a = avg_cost_any_from_sets(yhat, ids_te)\n",
        "\n",
        "        # діагностика якості single-label класифікатора\n",
        "        mF1    = f1_score(yte, yhat, average=\"macro\")\n",
        "        bacc   = balanced_accuracy_score(yte, yhat)\n",
        "\n",
        "        rows.append({\n",
        "            \"scenario\": scenario,\n",
        "            \"model\": model_key,\n",
        "            \"features\": float(len(X_cols)),\n",
        "            \"fold\": float(fold),\n",
        "            \"acc_any\": acc_a,\n",
        "            \"top2_any\": t2a,\n",
        "            \"group_acc\": gacc,\n",
        "            \"avg_cost_any\": cost_a,\n",
        "            \"macro_f1\": mF1,\n",
        "            \"balanced_acc\": bacc\n",
        "        })\n",
        "    return rows\n",
        "\n",
        "def run_hier(kind, df_use, X_cols, scenario):\n",
        "    rows = []\n",
        "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "    for fold, (tr, te) in enumerate(skf.split(df_use[X_cols], POS), 1):\n",
        "        Xtr, Xte = df_use.iloc[tr][X_cols], df_use.iloc[te][X_cols]\n",
        "        ytr_pos, yte_pos = POS.iloc[tr], POS.iloc[te]  # proxy\n",
        "        ytr_grp = GRP.iloc[tr]\n",
        "        ids_te = df_use.iloc[te][\"sofifa_id\"].astype(int).values\n",
        "\n",
        "        # 1) груповий класифікатор\n",
        "        pre_g   = make_preprocessor(X_cols, df_use)\n",
        "        grp_est = maybe_calibrate(make_group_estimator())\n",
        "        pipe_grp = Pipeline([(\"prep\", pre_g), (\"clf\", grp_est)])\n",
        "        pipe_grp.fit(Xtr, ytr_grp)\n",
        "        grp_classes = pipe_grp.named_steps[\"clf\"].classes_\n",
        "        Pgrp_te = pipe_grp.predict_proba(Xte)\n",
        "\n",
        "        # 2) моделі всередині груп\n",
        "        pos_models = {}\n",
        "        for g in [\"GK\",\"DEF\",\"MID\",\"FWD\"]:\n",
        "            idx_g = ytr_pos[ytr_pos.map(GMAP) == g].index\n",
        "            if len(idx_g) < 20:\n",
        "                continue\n",
        "            Xg = df_use.loc[idx_g, X_cols]\n",
        "            yg = ytr_pos.loc[idx_g]\n",
        "            le_g = LabelEncoder().fit(yg)\n",
        "            yg_enc = le_g.transform(yg)\n",
        "            pre_p = make_preprocessor(X_cols, df_use)\n",
        "            est_p = make_pos_estimator(kind, n_classes=len(le_g.classes_))\n",
        "            if est_p is None:\n",
        "                pos_models[g] = {\"only\": le_g.classes_[0]}\n",
        "                continue\n",
        "            est_p = maybe_calibrate(est_p)\n",
        "            pipe_pos = Pipeline([(\"prep\", pre_p), (\"clf\", est_p)])\n",
        "            pipe_pos.fit(Xg, yg_enc)\n",
        "            pos_models[g] = {\"pipe\": pipe_pos, \"le\": le_g}\n",
        "\n",
        "        # 3) змішування\n",
        "        unique_pos = np.array(sorted(POS.unique()))\n",
        "        pos_index  = {p:i for i,p in enumerate(unique_pos)}\n",
        "        Ppos_te    = np.zeros((len(Xte), len(unique_pos)))\n",
        "\n",
        "        for gi, gname in enumerate(grp_classes):\n",
        "            if gname not in pos_models:\n",
        "                continue\n",
        "            info = pos_models[gname]\n",
        "            if \"only\" in info:\n",
        "                only = info[\"only\"]\n",
        "                Ppos_te[:, pos_index[only]] += Pgrp_te[:, gi]\n",
        "                continue\n",
        "            P_cond = info[\"pipe\"].predict_proba(Xte)\n",
        "            cl_names = info[\"le\"].inverse_transform(np.arange(P_cond.shape[1]))\n",
        "            for ci, cname in enumerate(cl_names):\n",
        "                Ppos_te[:, pos_index[cname]] += Pgrp_te[:, gi] * P_cond[:, ci]\n",
        "\n",
        "        yhat_pos = unique_pos[Ppos_te.argmax(axis=1)]\n",
        "        # set-based метрики\n",
        "        acc_a  = acc_any_from_sets(yhat_pos, ids_te)\n",
        "        t2a    = topk_acc_any(Ppos_te, ids_te, unique_pos, k=2)\n",
        "        gacc   = group_acc_any(yhat_pos, ids_te)\n",
        "        cost_a = avg_cost_any_from_sets(yhat_pos, ids_te)\n",
        "        # діагностика\n",
        "        mF1    = f1_score(yte_pos, yhat_pos, average=\"macro\")\n",
        "        bacc   = balanced_accuracy_score(yte_pos, yhat_pos)\n",
        "\n",
        "        rows.append({\n",
        "            \"scenario\": scenario,\n",
        "            \"model\": f\"hier_{kind}\",\n",
        "            \"features\": float(len(X_cols)),\n",
        "            \"fold\": float(fold),\n",
        "            \"acc_any\": acc_a,\n",
        "            \"top2_any\": t2a,\n",
        "            \"group_acc\": gacc,\n",
        "            \"avg_cost_any\": cost_a,\n",
        "            \"macro_f1\": mF1,\n",
        "            \"balanced_acc\": bacc\n",
        "        })\n",
        "    return rows\n",
        "\n",
        "def run_ens(models, df_use, X_cols, scenario, name):\n",
        "    \"\"\"Soft-vote по ймовірностях FLAT моделей; метрики — лише set-based + діагностика.\"\"\"\n",
        "    rows = []\n",
        "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "    for fold, (tr, te) in enumerate(skf.split(df_use[X_cols], POS), 1):\n",
        "        Xtr, Xte = df_use.iloc[tr][X_cols], df_use.iloc[te][X_cols]\n",
        "        ytr, yte = POS.iloc[tr], POS.iloc[te]  # proxy\n",
        "        ids_te = df_use.iloc[te][\"sofifa_id\"].astype(int).values\n",
        "\n",
        "        classes_all = np.array(sorted(POS.unique()))\n",
        "        P_list = []\n",
        "\n",
        "        for key in models:\n",
        "            pre = make_preprocessor(X_cols, df_use)\n",
        "            est = make_flat_estimator(key)\n",
        "            est_c = maybe_calibrate(est)\n",
        "            pipe = Pipeline([(\"prep\", pre), (\"clf\", est_c)])\n",
        "\n",
        "            if key == \"flat_xgb\" and hasattr(est, \"fit\") and est.__class__.__name__.lower().startswith(\"xgb\"):\n",
        "                pipe.fit(Xtr, LE_POS.transform(ytr))\n",
        "                P = pipe.predict_proba(Xte)\n",
        "                cls = LE_POS.inverse_transform(pipe.named_steps[\"clf\"].classes_) \\\n",
        "                      if hasattr(pipe.named_steps[\"clf\"], \"classes_\") else classes_all\n",
        "            else:\n",
        "                pipe.fit(Xtr, ytr)\n",
        "                P = pipe.predict_proba(Xte)\n",
        "                cls = pipe.named_steps[\"clf\"].classes_\n",
        "\n",
        "            P_al = align_proba(P, cls, classes_all)\n",
        "            P_list.append(P_al)\n",
        "\n",
        "        P_avg = np.mean(P_list, axis=0)\n",
        "        yhat = classes_all[P_avg.argmax(axis=1)]\n",
        "\n",
        "        # set-based\n",
        "        acc_a  = acc_any_from_sets(yhat, ids_te)\n",
        "        t2a    = topk_acc_any(P_avg, ids_te, classes_all, k=2)\n",
        "        gacc   = group_acc_any(yhat, ids_te)\n",
        "        cost_a = avg_cost_any_from_sets(yhat, ids_te)\n",
        "        # діагностика\n",
        "        mF1    = f1_score(yte, yhat, average=\"macro\")\n",
        "        bacc   = balanced_accuracy_score(yte, yhat)\n",
        "\n",
        "        rows.append({\n",
        "            \"scenario\": scenario,\n",
        "            \"model\": name,\n",
        "            \"features\": float(len(X_cols)),\n",
        "            \"fold\": float(fold),\n",
        "            \"acc_any\": acc_a,\n",
        "            \"top2_any\": t2a,\n",
        "            \"group_acc\": gacc,\n",
        "            \"avg_cost_any\": cost_a,\n",
        "            \"macro_f1\": mF1,\n",
        "            \"balanced_acc\": bacc\n",
        "        })\n",
        "    return rows\n",
        "\n",
        "# ----------------------- Master run -----------------------\n",
        "all_rows = []\n",
        "\n",
        "for var_name, feat_list in VARIANTS.items():\n",
        "    for want_leak in [False, True]:\n",
        "        df_use, leak_cols = with_leak_df(df, want_leak)\n",
        "        X_cols = [c for c in feat_list if c in df_use.columns] + leak_cols\n",
        "        scenario = f\"{var_name}_{'with_leak' if want_leak else 'no_leak'}\"\n",
        "        print(f\"[{scenario}] Using {len(X_cols)} features\")\n",
        "\n",
        "        # FLAT\n",
        "        for key in [\"flat_lr\", \"flat_rf\", \"flat_hgb\", \"flat_xgb\"]:\n",
        "            try:\n",
        "                all_rows.extend(run_flat(key, df_use, X_cols, scenario))\n",
        "            except Exception as e:\n",
        "                print(f\"[WARN] skip {key} @ {scenario}: {e}\")\n",
        "\n",
        "        # HIER\n",
        "        for kind in ([\"xgb\",\"hgb\"] if True else [\"hgb\"]):\n",
        "            try:\n",
        "                all_rows.extend(run_hier(kind, df_use, X_cols, scenario))\n",
        "            except Exception as e:\n",
        "                print(f\"[WARN] skip hier_{kind} @ {scenario}: {e}\")\n",
        "\n",
        "        # ENSEMBLES\n",
        "        try:\n",
        "            all_rows.extend(run_ens([\"flat_lr\",\"flat_hgb\"], df_use, X_cols, scenario, name=\"ens_lr_hgb\"))\n",
        "        except Exception as e:\n",
        "            print(f\"[WARN] skip ens_lr_hgb @ {scenario}: {e}\")\n",
        "        try:\n",
        "            all_rows.extend(run_ens([\"flat_lr\",\"flat_hgb\",\"flat_xgb\"], df_use, X_cols, scenario, name=\"ens_lr_xgb_hgb\"))\n",
        "        except Exception as e:\n",
        "            print(f\"[WARN] skip ens_lr_xgb_hgb @ {scenario}: {e}\")\n",
        "\n",
        "res = pd.DataFrame(all_rows)\n",
        "res.to_csv(OUT_DIR/\"Task20_FULL_runs_detailed.csv\", index=False)\n",
        "\n",
        "grp = (res.groupby([\"scenario\",\"model\"], as_index=False)\n",
        "         .mean(numeric_only=True)\n",
        "         .sort_values([\"scenario\",\"acc_any\"], ascending=[True, False]))\n",
        "grp.to_csv(OUT_DIR/\"Task20_FULL_results_summary.csv\", index=False)\n",
        "\n",
        "print(\"\\n=== SUMMARY (усереднено по фолдах) — ключові set-метрики ===\")\n",
        "print(\n",
        "  grp[[\"scenario\",\"model\",\"features\",\"acc_any\",\"top2_any\",\"group_acc\",\"avg_cost_any\",\"macro_f1\",\"balanced_acc\"]]\n",
        "  .round(4).to_string(index=False)\n",
        ")\n",
        "print(f\"\\n[OK] Saved: {OUT_DIR/'Task20_FULL_runs_detailed.csv'} and {OUT_DIR/'Task20_FULL_results_summary.csv'}\")\n"
      ],
      "metadata": {
        "id": "X26n_PKhNMKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Висновки по Task20 (single-label, set-метрики)\n",
        "\n",
        "Головна метрика — acc_any (вгадали будь-яку із позицій гравця).\n",
        "\n",
        "Без підгляду (no_leak): найкраще A48_no_leak • ens_lr_hgb → 0.8807; B42_no_leak • ens_lr_hgb майже ідентично → 0.8803.\n",
        "\n",
        "З підглядом (with_leak): найкраще B42_with_leak • ens_lr_hgb → 0.9007, A48_with_leak • ens_lr_hgb → 0.9002.\n",
        "\n",
        "Що дає “leak” (club_position / nation_position):\n",
        "\n",
        "acc_any зростає приблизно на +0.020 (≈ +2 п.п.).\n",
        "\n",
        "avg_cost_any падає на ~0.035 (з ~0.206 → ~0.171), тобто помилки стають «дешевшими» за рахунок прямого підказування.\n",
        "\n",
        "top2_any зростає на ~+1.0 п.п. (≈ 0.947 → 0.958).\n",
        "\n",
        "Додаткові класифікаційні метрики (macro_f1/balanced_acc) теж підростають, але вони вторинні для нашої бізнес-мети.\n",
        "\n",
        "Чому так краще не робити у проді:\n",
        "\n",
        "club_position/nation_position — це фактично проксі таргету (часто прямо входять у список реальних позицій гравця).\n",
        "\n",
        "Така ознака недоступна або нелегітимна в інференсі «за скілами» (калькулятор амплуа від атрибутів), тож ми отримуємо завищені офлайн-оцінки і ризик деградації на нових даних.\n",
        "\n",
        "Є ризик витоку по часовій осі (оновлені ролі клубу/збірної вже «знають» поточну позицію) та перенавчання на метадані замість реальних навичок.\n",
        "\n",
        "A48 vs B42:\n",
        "Обидва фічсети дають практично однаковий рівень якості у всіх сценаріях (різниця в межах ±0.1 п.п.).\n",
        "\n",
        "A48 — фіксований, інтерпретований набір (48 ознак).\n",
        "\n",
        "B42 — авто-відбір (MI+RF, CV) — компактніший (41–43 після включення/виключення leak-колонок).\n",
        "\n",
        "По моделях:\n",
        "\n",
        "Плоскі моделі (особливо LR та ансамбль ens_lr_hgb) стабільно кращі.\n",
        "\n",
        "Ієрархія (group→position) програє ~1.5–3.0 п.п. по acc_any (накопичуються помилки на двох рівнях).\n",
        "\n",
        "XGB у нас не домінує над LR/HGB на цих фіча-матрицях."
      ],
      "metadata": {
        "id": "eHuCQxbux3Fm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task20 — Мультилейбл класифікація позицій гравця (set-based + вартісна метрика)\n",
        "\n",
        "Що прогнозуємо. Для кожного гравця відома множина реальних позицій T з поля player_positions (канонічні 15 ярликів). Модель повертає набір передбачених позицій P (до K штук, типово K=3). Мета — мінімізувати сумарний штраф за невідповідність множин, а не “вгадати одну головну” позицію.\n",
        "\n",
        "Простір ярликів і групи\n",
        "\n",
        "Використовуємо 15 канонічних позицій: GK, CB, LB, RB, LWB, RWB, CDM, CM, CAM, LM, RM, LW, RW, ST, CF.\n",
        "Для кожної позиції визначено групу: GK окремо; DEF = {CB, LB, RB, LWB, RWB}; MID = {CDM, CM, CAM, LM, RM}; FWD = {LW, RW, ST, CF}. Групи потрібні для градуйованих штрафів.\n",
        "\n",
        "Головна метрика: вартісна avg_set_cost (нижче — краще)\n",
        "\n",
        "Штраф рахується покомпонентно за зайві передбачення (FP) та пропущені істинні ярлики (FN). Для кожного гравця з істинною множиною T і предиктом P:\n",
        "\n",
        "За кожен FP p ∈ P \\ T:\n",
        "\n",
        "якщо group(p) збігається з хоч однією групою з T → +1.0 (помилка всередині правильної лінії),\n",
        "\n",
        "якщо group(p) інша за всі групи в T → +3.0 (переплутали лінії),\n",
        "\n",
        "якщо це польовий ↔ GK (напр., передбачили GK, коли в T лише DEF/MID/FWD, або навпаки) → +5.0 (найсильніший штраф).\n",
        "\n",
        "За кожен FN t ∈ T \\ P → +2.0 (пропустили реальну позицію).\n",
        "\n",
        "Пер-зразковий штраф: set_cost(T,P)=p∈P∖T∑​cFP​(p,T)+t∈T∖P∑​2.0\n",
        "\n",
        "Нормалізація (для зіставності між виборами K): set_cost_norm(T,P)=2⋅∣T∣+5⋅Kset_cost(T,P)​ ∈[0,1] де знаменник — “гірша межа” (пропустили всі істинні + передбачили K максимально хибних GK-помилок).\n",
        "Головний показник у звітах: avg_set_cost_norm (середнє по вибірці).\n",
        "\n",
        "Ця метрика прямо відбиває бізнес-вимогу: зайва позиція — погано, пропуск — теж погано; переплутати лінії гірше, а польовий↔GK — найгірше. Ідеал — P == T (нульовий штраф).\n",
        "\n",
        "Додаткові діагностики (для інтерпретації)\n",
        "\n",
        "acc_any — чи перетинаються множини (|P∩T|>0), інтуїтивний “хіт бодай по одній”.\n",
        "\n",
        "jaccard_samples — середній Jaccard |P∩T|/|P∪T|.\n",
        "\n",
        "micro_f1, macro_f1, hamming_loss — стандартні мультилейбл-метрики для звичного порівняння.\n",
        "\n",
        "У висновках пріоритезуємо avg_set_cost_norm; інші — як допоміжні.\n",
        "\n",
        "Керування кардинальністю (скільки ярликів прогнозуємо)\n",
        "\n",
        "Модель повертає ймовірності по 15 ярликах. Далі:\n",
        "\n",
        "Тюнінг порогів по кожному ярлику на валідації (сітка 0.2–0.5) для кращого F1 всередині класу.\n",
        "\n",
        "Обмеження кардинальності: лишаємо ярлики ≥ threshold, але обрізаємо до K найбільш імовірних (типово K=3). Якщо жоден не проходить — беремо топ-1 як fallback.\n",
        "\n",
        "Це дисциплінує |P| і напряму зменшує FP-штрафи.\n",
        "\n",
        "Моделі й препроцесинг\n",
        "\n",
        "One-Vs-Rest над базовими класифікаторами:\n",
        "\n",
        "LR (lbfgs, C≈1.5, max_iter≈3000–6000),\n",
        "\n",
        "HGB (HistGradientBoostingClassifier).\n",
        "\n",
        "Калібрування ймовірностей усередині OVR: CalibratedClassifierCV(method=\"sigmoid\", cv=3) — стабільніші пороги.\n",
        "\n",
        "Пайплайн: ColumnTransformer → числові StandardScaler(with_mean=False), категоріальні OneHotEncoder(handle_unknown=\"ignore\").\n",
        "\n",
        "CV: KFold(n_splits=5, shuffle=True, random_state=42).\n",
        "\n",
        "Вхідні ярлики конструюємо з player_positions (фільтр до канонічних 15), MultiLabelBinarizer.\n",
        "\n",
        "Вивід артефактів\n",
        "\n",
        "Фолдові метрики → out/tables/Task20_multilabel_folds.csv.\n",
        "\n",
        "Зведені середні → out/tables/Task20_multilabel_results.csv.\n",
        "У таблицях головні колонки: avg_set_cost_norm (↓), acc_any (↑), jaccard_samples (↑), micro_f1, macro_f1, hamming_loss."
      ],
      "metadata": {
        "id": "FrUdSKSqciSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Task20: Multilabel позиції — головна метрика avg_set_cost_norm\n",
        "from pathlib import Path\n",
        "import warnings, numpy as np, pandas as pd\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MultiLabelBinarizer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "\n",
        "# ----------------------- Конфіг ----------------------------------------------\n",
        "SEED        = 42\n",
        "N_SPLITS    = 5\n",
        "CALIBRATE   = True            # калібрування для небінарних базових (HGB)\n",
        "K_CAP       = 3               # верхня межа кількості предиктів на гравця (обрізаємо до топ-K)\n",
        "THR_GRID    = (0.2, 0.3, 0.4, 0.5)  # сітка для тюнінгу порогів по кожному ярлику\n",
        "\n",
        "# Ваги штрафів (бізнес-логіка)\n",
        "FP_INTRA    = 1.0   # зайва позиція в межах правильної лінії\n",
        "FP_CROSS    = 3.0   # зайва позиція з іншої лінії\n",
        "FP_GK       = 5.0   # польовий ↔ GK (найгірший хибний позитив)\n",
        "FN_W        = 2.0   # пропуск істинної позиції\n",
        "\n",
        "# Канонічні ярлики і групи\n",
        "CANON15 = [\"GK\",\"CB\",\"LB\",\"RB\",\"LWB\",\"RWB\",\"CDM\",\"CM\",\"CAM\",\"LM\",\"RM\",\"LW\",\"RW\",\"ST\",\"CF\"]\n",
        "CANON15_SET = set(CANON15)\n",
        "\n",
        "DEF = {\"CB\",\"LB\",\"RB\",\"LWB\",\"RWB\"}\n",
        "MID = {\"CDM\",\"CM\",\"CAM\",\"LM\",\"RM\"}\n",
        "FWD = {\"ST\",\"CF\",\"LW\",\"RW\"}\n",
        "def group_of(pos: str) -> str:\n",
        "    p = str(pos).upper()\n",
        "    if p == \"GK\": return \"GK\"\n",
        "    if p in DEF:  return \"DEF\"\n",
        "    if p in MID:  return \"MID\"\n",
        "    if p in FWD:  return \"FWD\"\n",
        "    return \"OTHER\"\n",
        "\n",
        "# Шляхи\n",
        "RAW_CSV   = Path(\"data/raw/fifa_players.csv\")\n",
        "IN_FE     = Path(\"out/tables/Task18_features_train.csv\")\n",
        "IN_SEL_B  = Path(\"out/tables/Task19_selected_features_B.csv\")  # використовуємо лише B\n",
        "OUT       = Path(\"out/tables\"); OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ----------------------- Дані -------------------------------------------------\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "df = pd.read_csv(IN_FE, low_memory=False)\n",
        "sel = pd.read_csv(IN_SEL_B)[\"feature\"].tolist()  # фічсет B (автовідбір)\n",
        "\n",
        "# Парсинг множин позицій із player_positions\n",
        "def parse_positions(s):\n",
        "    if pd.isna(s): return []\n",
        "    toks = [t.strip().upper() for t in str(s).split(\",\") if t.strip()]\n",
        "    return [t for t in toks if t in CANON15_SET]\n",
        "\n",
        "# Патч: якщо немає або частково відсутні 'player_positions' у train-матриці — доточуємо з RAW\n",
        "need_patch = (\"player_positions\" not in df.columns) or df[\"player_positions\"].isna().any()\n",
        "if need_patch:\n",
        "    if not RAW_CSV.exists():\n",
        "        raise FileNotFoundError(\"Немає RAW (data/raw/fifa_players.csv), щоб заповнити 'player_positions'.\")\n",
        "    raw_pp = (pd.read_csv(RAW_CSV, usecols=[\"sofifa_id\",\"player_positions\"], low_memory=False)\n",
        "                .drop_duplicates(\"sofifa_id\").set_index(\"sofifa_id\"))\n",
        "    before = df.shape[0]\n",
        "    miss_before = df[\"player_positions\"].isna().sum() if \"player_positions\" in df.columns else df.shape[0]\n",
        "    df = df.set_index(\"sofifa_id\")\n",
        "    if \"player_positions\" not in df.columns:\n",
        "        df[\"player_positions\"] = np.nan\n",
        "    df.loc[df[\"player_positions\"].isna(), \"player_positions\"] = raw_pp.reindex(df.index)[\"player_positions\"]\n",
        "    df = df.reset_index()\n",
        "    miss_after = df[\"player_positions\"].isna().sum()\n",
        "\n",
        "\n",
        "if \"player_positions\" not in df.columns:\n",
        "    raise ValueError(\"Немає 'player_positions' у Task18_features_train.csv — потрібен для мультилейбл-цілі.\")\n",
        "\n",
        "y_sets = df[\"player_positions\"].apply(parse_positions)\n",
        "mask_ok = y_sets.apply(lambda xs: len(xs) > 0)\n",
        "df = df.loc[mask_ok].copy()\n",
        "y_sets = y_sets.loc[mask_ok]\n",
        "\n",
        "# Ознаки: лише ті, що реально є в df\n",
        "base_feats = [c for c in sel if c in df.columns]\n",
        "if not base_feats:\n",
        "    raise ValueError(\"Порожній набір ознак: жодної з вибраних фіч із Task19_selected_features_B.csv не знайдено в матриці.\")\n",
        "X = df[base_feats].copy()\n",
        "\n",
        "# ----------------------- Препроцесинг ----------------------------------------\n",
        "def make_preprocessor(X_ref: pd.DataFrame):\n",
        "    num_cols = [c for c in X_ref.columns if pd.api.types.is_numeric_dtype(X_ref[c])]\n",
        "    cat_cols = [c for c in X_ref.columns if not pd.api.types.is_numeric_dtype(X_ref[c])]\n",
        "    return ColumnTransformer([\n",
        "        (\"num\", StandardScaler(with_mean=False), num_cols),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols)\n",
        "    ], remainder=\"drop\")\n",
        "\n",
        "mlb = MultiLabelBinarizer(classes=CANON15)\n",
        "Y = mlb.fit_transform(y_sets)\n",
        "\n",
        "# ----------------------- Базові моделі ----------------------------------------\n",
        "def make_base_est(kind=\"hgb\"):\n",
        "    if kind == \"lr\":\n",
        "        return LogisticRegression(\n",
        "            C=1.5, max_iter=6000, solver=\"lbfgs\", n_jobs=-1, random_state=SEED\n",
        "        )\n",
        "    # default → HGB + калібрування (дає надійніші predict_proba в OVR)\n",
        "    est = HistGradientBoostingClassifier(random_state=SEED)\n",
        "    if CALIBRATE:\n",
        "        est = CalibratedClassifierCV(estimator=est, method=\"sigmoid\", cv=3)\n",
        "    return est\n",
        "\n",
        "# ----------------------- Тюнінг порогів і обрізання до K ----------------------\n",
        "def choose_thresholds(y_true_bin, y_proba, grid=THR_GRID):\n",
        "    thr = np.full(y_proba.shape[1], 0.5, dtype=float)\n",
        "    for j in range(y_proba.shape[1]):\n",
        "        yt = y_true_bin[:, j]\n",
        "        if yt.sum() == 0:\n",
        "            thr[j] = 0.5\n",
        "            continue\n",
        "        pj = y_proba[:, j]\n",
        "        best_f1, best_t = -1.0, 0.5\n",
        "        for t in grid:\n",
        "            pred = (pj >= t).astype(int)\n",
        "            f1 = f1_score(yt, pred, zero_division=0)\n",
        "            if f1 > best_f1:\n",
        "                best_f1, best_t = f1, t\n",
        "        thr[j] = best_t\n",
        "    return thr\n",
        "\n",
        "def apply_thresholds_limit(P_val, thr, k_cap=K_CAP):\n",
        "    \"\"\"Пороги по класах + обрізання до топ-k_cap. Якщо нічого не пройшло — беремо топ-1.\"\"\"\n",
        "    Yb = (P_val >= thr[np.newaxis, :]).astype(int)\n",
        "    Yhat = np.zeros_like(Yb)\n",
        "    for i in range(P_val.shape[0]):\n",
        "        idx = np.where(Yb[i] == 1)[0].tolist()\n",
        "        if len(idx) == 0:\n",
        "            j = int(np.argmax(P_val[i]))\n",
        "            idx = [j]\n",
        "        if len(idx) > k_cap:\n",
        "            order = np.argsort(P_val[i][idx])[::-1][:k_cap]\n",
        "            idx = [idx[o] for o in order]\n",
        "        Yhat[i, idx] = 1\n",
        "    return Yhat\n",
        "\n",
        "# ----------------------- Вартісна метрика -------------------------------------\n",
        "def set_cost_one(T_labels: list[str], P_labels: list[str]) -> float:\n",
        "    \"\"\"Ненормована вартість для одного гравця (чим менше — тим краще).\"\"\"\n",
        "    T = set(T_labels)\n",
        "    P = set(P_labels)\n",
        "\n",
        "    # FP\n",
        "    cost = 0.0\n",
        "    T_groups = {group_of(t) for t in T}\n",
        "    has_gk_T = (\"GK\" in T_groups)\n",
        "    for p in (P - T):\n",
        "        gp = group_of(p)\n",
        "        # польовий ↔ GK\n",
        "        if (gp == \"GK\" and not has_gk_T) or (gp != \"GK\" and has_gk_T):\n",
        "            cost += FP_GK\n",
        "        else:\n",
        "            cost += FP_INTRA if gp in T_groups else FP_CROSS\n",
        "\n",
        "    # FN\n",
        "    fn = len(T - P)\n",
        "    cost += FN_W * fn\n",
        "    return cost\n",
        "\n",
        "def avg_set_cost_norm(Y_true_bin: np.ndarray, Y_pred_bin: np.ndarray, classes: list[str], k_cap=K_CAP):\n",
        "    \"\"\"Середня нормована вартість (↓ краще). Нормалізуємо на FN_W*|T| + FP_GK*K_cap для кожного зразка.\"\"\"\n",
        "    costs, norms = [], []\n",
        "    for i in range(Y_true_bin.shape[0]):\n",
        "        T = [classes[j] for j in np.where(Y_true_bin[i] == 1)[0]]\n",
        "        P = [classes[j] for j in np.where(Y_pred_bin[i] == 1)[0]]\n",
        "        c = set_cost_one(T, P)\n",
        "        denom = FN_W * len(T) + FP_GK * k_cap\n",
        "        denom = max(denom, 1e-9)\n",
        "        costs.append(c)\n",
        "        norms.append(c / denom)\n",
        "    return float(np.mean(costs)), float(np.mean(norms))\n",
        "\n",
        "def acc_any(y_true_bin, y_pred_bin):\n",
        "    inter = ((y_true_bin & y_pred_bin).sum(axis=1) > 0)\n",
        "    return float(inter.mean())\n",
        "\n",
        "def jaccard_samples(y_true_bin, y_pred_bin):\n",
        "    inter = (y_true_bin & y_pred_bin).sum(axis=1)\n",
        "    union = (y_true_bin | y_pred_bin).sum(axis=1)\n",
        "    union = np.where(union == 0, 1, union)\n",
        "    return float((inter / union).mean())\n",
        "\n",
        "# ----------------------- Крос-вал і оцінка ------------------------------------\n",
        "def run_multilabel(kind=\"hgb\"):\n",
        "    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
        "    rows = []\n",
        "    for fold, (tr, te) in enumerate(kf.split(X), 1):\n",
        "        Xtr, Xte = X.iloc[tr], X.iloc[te]\n",
        "        Ytr, Yte = Y[tr], Y[te]\n",
        "\n",
        "        pre  = make_preprocessor(Xtr)\n",
        "        base = make_base_est(kind)\n",
        "        clf  = OneVsRestClassifier(base, n_jobs=-1)\n",
        "        pipe = Pipeline([(\"prep\", pre), (\"clf\", clf)])\n",
        "\n",
        "        # навчання\n",
        "        pipe.fit(Xtr, Ytr)\n",
        "\n",
        "        # ймовірності для тюнінгу порогів\n",
        "        try:\n",
        "            P_val = pipe.predict_proba(Xte)\n",
        "        except Exception:\n",
        "            try:\n",
        "                D_val = pipe.decision_function(Xte)\n",
        "                P_val = 1.0 / (1.0 + np.exp(-D_val))\n",
        "            except Exception:\n",
        "                P_val = pipe.predict(Xte).astype(float)\n",
        "\n",
        "        thr = choose_thresholds(Yte, P_val, grid=THR_GRID)\n",
        "        Yhat = apply_thresholds_limit(P_val, thr, k_cap=K_CAP)\n",
        "\n",
        "        # метрики\n",
        "        subset_acc = accuracy_score(Yte, Yhat)                 # повний збіг множин\n",
        "        micro_f1   = f1_score(Yte, Yhat, average=\"micro\", zero_division=0)\n",
        "        macro_f1   = f1_score(Yte, Yhat, average=\"macro\", zero_division=0)\n",
        "        ham_loss   = hamming_loss(Yte, Yhat)\n",
        "        jacc       = jaccard_samples(Yte, Yhat)\n",
        "        any_hit    = acc_any(Yte, Yhat)\n",
        "        cost_raw, cost_norm = avg_set_cost_norm(Yte, Yhat, classes=list(mlb.classes_), k_cap=K_CAP)\n",
        "\n",
        "        rows.append({\n",
        "            \"feat_set\": \"B\", \"model\": f\"ovr_{kind}\",\n",
        "            \"fold\": float(fold),\n",
        "            \"subset_acc\": subset_acc,\n",
        "            \"micro_f1\": micro_f1,\n",
        "            \"macro_f1\": macro_f1,\n",
        "            \"hamming_loss\": ham_loss,\n",
        "            \"jaccard_samples\": jacc,\n",
        "            \"acc_any\": any_hit,\n",
        "            \"avg_set_cost\": cost_raw,\n",
        "            \"avg_set_cost_norm\": cost_norm,\n",
        "            \"avg_true_card\": float(Yte.sum(axis=1).mean()),\n",
        "            \"avg_pred_card\": float(Yhat.sum(axis=1).mean()),\n",
        "            \"n_features\": float(len(base_feats)),\n",
        "            \"K_cap\": float(K_CAP)\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "res_lr  = run_multilabel(\"lr\")\n",
        "res_hgb = run_multilabel(\"hgb\")\n",
        "\n",
        "res = pd.concat([res_lr, res_hgb], ignore_index=True)\n",
        "res_grp = (res.groupby([\"feat_set\",\"model\"], as_index=False)\n",
        "              .mean(numeric_only=True)\n",
        "              .sort_values([\"avg_set_cost_norm\",\"jaccard_samples\",\"acc_any\"],\n",
        "                           ascending=[True, False, False]))\n",
        "\n",
        "# збереження\n",
        "res.to_csv(OUT/\"Task20_multilabel_folds.csv\", index=False)\n",
        "res_grp.to_csv(OUT/\"Task20_multilabel_results.csv\", index=False)\n",
        "\n",
        "# друк (додаємо subset_acc у підсумковий звіт)\n",
        "cols = [\"feat_set\",\"model\",\"n_features\",\"K_cap\",\n",
        "        \"avg_set_cost_norm\",\"avg_set_cost\",\n",
        "        \"jaccard_samples\",\"acc_any\",\"subset_acc\",\"micro_f1\",\"macro_f1\",\"hamming_loss\",\n",
        "        \"avg_true_card\",\"avg_pred_card\"]\n",
        "print(res_grp[cols].round(4).to_string(index=False))\n",
        "print(f\"[OK] Saved: {OUT/'Task20_multilabel_folds.csv'}, {OUT/'Task20_multilabel_results.csv'}\")\n"
      ],
      "metadata": {
        "id": "AMp812NZciqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мета блоку: запакувати найкращу одноярликову модель у форматі, готовому до прод-інференсу (Streamlit/скрипт), разом з метаданими.\n",
        "\n",
        "Що робить:\n",
        "\n",
        "Читає Task20_FULL_results_summary.csv, знаходить найкращий flat-варіант серед flat_lr, flat_hgb, flat_rf за acc_any.\n",
        "\n",
        "Відновлює точний сценарій (A48/B42 × with_leak/no_leak), збирає правильний фічсет.\n",
        "\n",
        "Навчає повний пайплайн (preprocessor + classifier) на всьому train-наборі; для дерев/бустінгу — калібрує (isotonic, CV=3).\n",
        "\n",
        "Зберігає в models/:\n",
        "\n",
        "task20_singlelabel_<scenario>_<model>_<timestamp>.pkl — sklearn-пайплайн (готовий predict_proba/predict).\n",
        "\n",
        "task20_singlelabel_<...>.metadata.json — класи, список ознак, сценарій, прапор калібрування, тощо.\n",
        "\n",
        "Навіщо так: таймштамповані файли не перезаписують попередні артефакти та полегшують відкат/аудит. Метадані потрібні для відтворюваності та сервісу.\n",
        "\n",
        "Примітки:\n",
        "\n",
        "Якщо найкращим виявився ансамбль/ієрархія/flat_xgb, блок автоматично візьме наступний кращий підтримуваний flat."
      ],
      "metadata": {
        "id": "KMdwGJTtqVm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Висновки (multilabel, фічсет B, K_cap=3)\n",
        "\n",
        "Найкраще спрацювала OVR-Logistic Regression:\n",
        "\n",
        "avg_set_cost_norm ↓ 0.0980 (нижче = краще) — на ~13% менше штрафу, ніж у HGB (0.1128).\n",
        "\n",
        "subset_acc ↑ 0.4358 проти 0.4038 у HGB — майже у 44% кейсів ми відтворюємо повний список позицій гравця.\n",
        "\n",
        "Узгоджені додаткові метрики:\n",
        "\n",
        "acc_any = 0.9535 — у 95% випадків вгадуємо хоч одну з істинних позицій.\n",
        "\n",
        "jaccard_samples = 0.6696 — у середньому ~2/3 перетину між істинним та передбаченим множинами.\n",
        "\n",
        "micro_f1 = 0.7031, macro_f1 = 0.5859, hamming_loss = 0.0694.\n",
        "\n",
        "Кардинальність множин: істина avg_true_card = 1.66, прогноз avg_pred_card = 1.84 — помірна схильність до надлишкових передбачених позицій, але в межах наших штрафів це прийнятний компроміс: низький avg_set_cost_norm підтверджує, що «зайві» позиції здебільшого не коштують дорого.\n",
        "\n",
        "Бізнес-інтерпретація.\n",
        "Модель LR забезпечує низьку середню вартість помилок і високу практичну корисність: у 95% гравців вона потрапляє в одну з їхніх позицій, а майже в половині випадків — відтворює весь набір. Це робить її хорошим вибором за нашою головною метрикою avg_set_cost_norm (мінімізуємо штрафи) при збереженні адекватної точності повного збігу (subset_acc)."
      ],
      "metadata": {
        "id": "7WXLPmZq00C0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === (Optional) Export best single-label model (flat LR/HGB/RF) + metadata ===\n",
        "import json, time, joblib\n",
        "from pathlib import Path\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "SEED = 42\n",
        "CALIBRATE = True\n",
        "\n",
        "RAW_CSV = Path(\"data/raw/fifa_players.csv\")\n",
        "IN_FE   = Path(\"out/tables/Task18_features_train.csv\")\n",
        "SUM_CSV = Path(\"out/tables/Task20_FULL_results_summary.csv\")\n",
        "SEL_B42 = Path(\"out/tables/Task19_selected_features_B.csv\")  # 42 фічі з блоку 6\n",
        "OUTM    = Path(\"models\"); OUTM.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "SUPPORTED_FLAT = {\"flat_lr\", \"flat_hgb\", \"flat_rf\"}  # що вміємо пакувати\n",
        "\n",
        "# --- helpers ---\n",
        "def OHE_dense():\n",
        "    try:\n",
        "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "    except TypeError:\n",
        "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
        "\n",
        "def make_preprocessor(X_cols, dfref):\n",
        "    num_cols = [c for c in X_cols if pd.api.types.is_numeric_dtype(dfref[c])]\n",
        "    cat_cols = [c for c in X_cols if not pd.api.types.is_numeric_dtype(dfref[c])]\n",
        "    return ColumnTransformer([\n",
        "        (\"num\", StandardScaler(with_mean=False), num_cols),\n",
        "        (\"cat\", OHE_dense(), cat_cols)\n",
        "    ], remainder=\"drop\")\n",
        "\n",
        "def with_leak_df(df_in: pd.DataFrame, want_leak: bool):\n",
        "    if not want_leak:\n",
        "        return df_in.copy(), []\n",
        "    if \"sofifa_id\" in df_in.columns and RAW_CSV.exists():\n",
        "        raw = (pd.read_csv(RAW_CSV, usecols=[\"sofifa_id\",\"club_position\",\"nation_position\"])\n",
        "                 .drop_duplicates(\"sofifa_id\").set_index(\"sofifa_id\"))\n",
        "        df2 = df_in.copy()\n",
        "        leak_cols = []\n",
        "        for c in [\"club_position\",\"nation_position\"]:\n",
        "            if c in raw.columns:\n",
        "                df2[c] = df2[\"sofifa_id\"].map(raw[c])\n",
        "                leak_cols.append(c)\n",
        "        return df2, leak_cols\n",
        "    return df_in.copy(), []\n",
        "\n",
        "def make_estimator(key):\n",
        "    if key == \"flat_lr\":\n",
        "        return LogisticRegression(C=1.5, max_iter=6000, solver=\"lbfgs\", n_jobs=-1, random_state=SEED)\n",
        "    if key == \"flat_rf\":\n",
        "        return RandomForestClassifier(n_estimators=600, min_samples_leaf=2, n_jobs=-1, random_state=SEED)\n",
        "    if key == \"flat_hgb\":\n",
        "        return HistGradientBoostingClassifier(random_state=SEED)\n",
        "    raise ValueError(\"Unsupported model for export\")\n",
        "\n",
        "def build_A48_alt(dfref):\n",
        "    # фіксований каркас + добір технічних до 48\n",
        "    must = [\"overall\",\"potential\",\"age\",\"height_cm\",\"weight_kg\",\n",
        "            \"weak_foot\",\"skill_moves\",\"international_reputation\",\n",
        "            \"pace_idx\",\"dribble_idx\",\"playmake_idx\",\"attack_idx\",\"defend_idx\",\"phys_idx\",\"gk_idx\",\n",
        "            \"work_rate\",\"preferred_foot\",\"body_type\",\"work_att\",\"work_def\"]\n",
        "    cols = [c for c in must if c in dfref.columns]\n",
        "    patterns = (\"attacking_\",\"skill_\",\"movement_\",\"mentality_\",\"power_\",\"defending_\",\"goalkeeping_\")\n",
        "    detail = [c for c in dfref.columns if c.startswith(patterns)]\n",
        "    num_detail = [c for c in detail if pd.api.types.is_numeric_dtype(dfref[c])]\n",
        "    if \"overall\" in dfref.columns and len(num_detail) > 0:\n",
        "        corr = dfref[num_detail].corrwith(dfref[\"overall\"]).abs().sort_values(ascending=False)\n",
        "        for c in corr.index:\n",
        "            if len(cols) >= 48: break\n",
        "            if c not in cols:\n",
        "                cols.append(c)\n",
        "    return cols[:48]\n",
        "\n",
        "# --- pick best supported flat setup by acc_any ---\n",
        "summary = pd.read_csv(SUM_CSV)\n",
        "cand = summary[summary[\"model\"].isin(SUPPORTED_FLAT)].copy()\n",
        "if cand.empty:\n",
        "    raise RuntimeError(\"Немає жодної підтримуваної плоскої моделі для експорту (flat_lr/flat_hgb/flat_rf).\")\n",
        "best = cand.sort_values([\"acc_any\"], ascending=False).iloc[0]\n",
        "scenario = best[\"scenario\"]  # e.g., A48_with_leak\n",
        "model_key = best[\"model\"]    # flat_lr / flat_hgb / flat_rf\n",
        "print(f\"[best for export] scenario={scenario}, model={model_key}, acc_any={best['acc_any']:.4f}\")\n",
        "\n",
        "# --- load data & features for that scenario ---\n",
        "df = pd.read_csv(IN_FE, low_memory=False)\n",
        "POS = df[\"primary_position\"].astype(str)\n",
        "\n",
        "sel_B = pd.read_csv(SEL_B42)[\"feature\"].tolist()\n",
        "sel_B = sel_B[:42] if len(sel_B) > 42 else sel_B\n",
        "sel_A = build_A48_alt(df)\n",
        "\n",
        "if scenario.startswith(\"B42_\"):\n",
        "    feat_list = sel_B\n",
        "elif scenario.startswith(\"A48_\"):\n",
        "    feat_list = sel_A\n",
        "else:\n",
        "    raise ValueError(f\"Unknown scenario prefix in '{scenario}' (expect A48_* or B42_*)\")\n",
        "\n",
        "want_leak = scenario.endswith(\"_with_leak\")\n",
        "df_use, leak_cols = with_leak_df(df, want_leak)\n",
        "X_cols = [c for c in feat_list if c in df_use.columns] + leak_cols\n",
        "print(f\"[export] Using {len(X_cols)} features ({'with' if want_leak else 'no'}_leak)\")\n",
        "\n",
        "# --- fit full-train pipeline ---\n",
        "pre = make_preprocessor(X_cols, df_use)\n",
        "est = make_estimator(model_key)\n",
        "clf = CalibratedClassifierCV(est, method=\"isotonic\", cv=3) if CALIBRATE and isinstance(est, (HistGradientBoostingClassifier, RandomForestClassifier)) else est\n",
        "pipe = Pipeline([(\"prep\", pre), (\"clf\", clf)])\n",
        "pipe.fit(df_use[X_cols], POS)\n",
        "\n",
        "# --- save pkl + metadata ---\n",
        "stamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "fname_base = f\"task20_singlelabel_{scenario}_{model_key}_{stamp}\"\n",
        "pkl_path = OUTM / f\"{fname_base}.pkl\"\n",
        "meta_path = OUTM / f\"{fname_base}.metadata.json\"\n",
        "\n",
        "joblib.dump(pipe, pkl_path)\n",
        "\n",
        "meta = {\n",
        "    \"scenario\": scenario,\n",
        "    \"model\": model_key,\n",
        "    \"features\": X_cols,\n",
        "    \"n_features\": len(X_cols),\n",
        "    \"classes\": sorted(POS.unique()),\n",
        "    \"seed\": SEED,\n",
        "    \"calibrated\": bool(CALIBRATE and isinstance(est, (HistGradientBoostingClassifier, RandomForestClassifier))),\n",
        "    \"selected_from\": str(SUM_CSV),\n",
        "}\n",
        "with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"✅ Saved:\", pkl_path)\n",
        "print(\"✅ Saved:\", meta_path)\n"
      ],
      "metadata": {
        "id": "J8BQC0jpqUor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мета блоку: зібрати маніфест артефактів Task20 (таблиці якості та збережені моделі), перевірити їх на існування/непорожність і синхронізувати у GitHub.\n",
        "\n",
        "Що робить:\n",
        "\n",
        "Перевіряє ключові CSV:\n",
        "\n",
        "out/tables/Task20_FULL_runs_detailed.csv, out/tables/Task20_FULL_results_summary.csv\n",
        "\n",
        "out/tables/Task20_multilabel_folds.csv, out/tables/Task20_multilabel_results.csv\n",
        "\n",
        "Автоматично інвентаризує всі models/*.pkl і models/*.json (без жорстких імен).\n",
        "\n",
        "Формує маніфест _manifest_task20_models.csv із розміром, head-рядками для CSV і mtime.\n",
        "\n",
        "Комітить/пушить артефакти в репозиторій (гілка/токен — параметри блоку).\n",
        "\n",
        "Додатково може додати сервісні файли (app.py, config.yaml, requirements.txt, тощо).\n",
        "\n",
        "Як читати:\n",
        "\n",
        "✅ — файл існує і має ненульовий розмір (для CSV ще й читається head).\n",
        "\n",
        "❌ — відсутній/порожній (перевірте попередні кроки або шляхи).\n",
        "\n",
        "Гнучкість:\n",
        "\n",
        "STRICT=False — лише друк попереджень; True — падіння з assert (зручно для CI).\n",
        "\n",
        "Шаблони додаткових файлів — у EXTRA_GLOBS."
      ],
      "metadata": {
        "id": "gcmZ4eVFo97S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Task20: Перевірка артефактів моделей + Sync у GitHub =====================\n",
        "import os, glob, json, getpass, subprocess, shlex, time\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# ── Налаштування репо / пушу ──────────────────────────────────────────────────\n",
        "WORKDIR   = \"/content/project_fifa_players\"        # корінь клонованого репо\n",
        "BRANCH    = \"main\"                                 # цільова гілка\n",
        "REPO_SLUG = \"rvkushnir/project_fifa_players\"       # user/repo\n",
        "FORCE_ADD_IF_IGNORED = False                       # git add -f\n",
        "\n",
        "# ── Шляхи/каталоги ────────────────────────────────────────────────────────────\n",
        "OUT = Path(\"out/tables\")\n",
        "MODELS_DIR = Path(\"models\")\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ── Очікувані CSV (Task20) ────────────────────────────────────────────────────\n",
        "EXPECTED_CSV = [\n",
        "    # single-label\n",
        "    \"Task20_FULL_runs_detailed.csv\",\n",
        "    \"Task20_FULL_results_summary.csv\",\n",
        "    # multilabel\n",
        "    \"Task20_multilabel_folds.csv\",\n",
        "    \"Task20_multilabel_results.csv\",\n",
        "]\n",
        "\n",
        "# Додатково пушимо ці патерни (не обовʼязково)\n",
        "EXTRA_GLOBS = [\n",
        "    \"app.py\",\n",
        "    \"config.yaml\",\n",
        "    \"requirements.txt\",\n",
        "    \"scripts/export_best_model.py\",\n",
        "]\n",
        "\n",
        "# Грубість перевірки: False → друк попереджень; True → падіння з assert\n",
        "STRICT = False\n",
        "\n",
        "# ── Утиліти ───────────────────────────────────────────────────────────────────\n",
        "def run(cmd, check=True, capture=False):\n",
        "    print(\"$\", cmd)\n",
        "    if capture:\n",
        "        return subprocess.run(shlex.split(cmd), check=check, capture_output=True, text=True)\n",
        "    return subprocess.run(shlex.split(cmd), check=check)\n",
        "\n",
        "def exists(p: Path) -> bool:\n",
        "    return p.exists() and (p.stat().st_size > 0)\n",
        "\n",
        "# ── 0) Робоча тека ────────────────────────────────────────────────────────────\n",
        "os.makedirs(WORKDIR, exist_ok=True)\n",
        "os.chdir(WORKDIR)\n",
        "print(\"pwd:\", os.getcwd())\n",
        "\n",
        "# ── 1) Побудова маніфесту по CSV та models/* ──────────────────────────────────\n",
        "rows = []\n",
        "\n",
        "# CSV з OUT\n",
        "for name in EXPECTED_CSV:\n",
        "    p = OUT / name\n",
        "    info = {\n",
        "        \"bucket\": \"tables\",\n",
        "        \"path\": str(p),\n",
        "        \"exists\": p.exists(),\n",
        "        \"size\": int(p.stat().st_size) if p.exists() else 0,\n",
        "        \"mtime\": time.ctime(p.stat().st_mtime) if p.exists() else \"-\",\n",
        "        \"head_rows\": \"-\"\n",
        "    }\n",
        "    if p.suffix == \".csv\" and p.exists() and p.stat().st_size > 0:\n",
        "        try:\n",
        "            info[\"head_rows\"] = pd.read_csv(p, nrows=3).shape[0]\n",
        "        except Exception:\n",
        "            info[\"head_rows\"] = \"?\"\n",
        "    rows.append(info)\n",
        "\n",
        "# Усі моделі/метадані з MODELS_DIR\n",
        "model_files = sorted(MODELS_DIR.glob(\"*.pkl\"))\n",
        "meta_files  = sorted(MODELS_DIR.glob(\"*.json\"))\n",
        "for p in model_files + meta_files:\n",
        "    rows.append({\n",
        "        \"bucket\": \"models\",\n",
        "        \"path\": str(p),\n",
        "        \"exists\": p.exists(),\n",
        "        \"size\": int(p.stat().st_size),\n",
        "        \"mtime\": time.ctime(p.stat().st_mtime),\n",
        "        \"head_rows\": \"-\"\n",
        "    })\n",
        "\n",
        "man = pd.DataFrame(rows).sort_values([\"bucket\",\"path\"])\n",
        "man_path = OUT / \"_manifest_task20_models.csv\"\n",
        "man.to_csv(man_path, index=False)\n",
        "\n",
        "print(\"\\n=== Task20 Models Manifest ===\")\n",
        "ok = True\n",
        "for _, r in man.iterrows():\n",
        "    mark = \"✅\" if (r[\"exists\"] and r[\"size\"] > 0) else \"❌\"\n",
        "    print(f'{mark} {r[\"bucket\"]:<8} | {os.path.basename(r[\"path\"]):45s} | size={r[\"size\"]:>8} | head={r[\"head_rows\"]!s:<3} | {r[\"mtime\"]}')\n",
        "    if r[\"bucket\"] == \"tables\" and not (r[\"exists\"] and r[\"size\"] > 0):\n",
        "        ok = False  # таблиці вважаємо обовʼязковими\n",
        "\n",
        "print(f\"\\nМаніфест збережено → {man_path}\")\n",
        "\n",
        "if STRICT:\n",
        "    assert ok, \"Є відсутні або порожні таблиці Task20.\"\n",
        "\n",
        "# ── 2) Git-конфіг автора (безпечно, якщо вже задано) ─────────────────────────\n",
        "run('git config user.name \"rvkushnir\"', check=False)\n",
        "run('git config user.email \"rvkushnir@gmail.com\"', check=False)\n",
        "\n",
        "# ── 3) Додаємо файли у staging ────────────────────────────────────────────────\n",
        "added_files = []\n",
        "\n",
        "# CSV\n",
        "for name in EXPECTED_CSV:\n",
        "    p = OUT / name\n",
        "    if p.exists():\n",
        "        cmd = f'git add{\" -f\" if FORCE_ADD_IF_IGNORED else \"\"} {shlex.quote(str(p))}'\n",
        "        run(cmd, check=False)\n",
        "        added_files.append(str(p))\n",
        "\n",
        "# Маніфест\n",
        "if man_path.exists():\n",
        "    run(f'git add {shlex.quote(str(man_path))}', check=False)\n",
        "    added_files.append(str(man_path))\n",
        "\n",
        "# Моделі + метадані (усі знайдені)\n",
        "for p in model_files + meta_files:\n",
        "    run(f'git add {shlex.quote(str(p))}', check=False)\n",
        "    added_files.append(str(p))\n",
        "\n",
        "# Додаткові патерни (не обовʼязково)\n",
        "for pat in EXTRA_GLOBS:\n",
        "    for p in glob.glob(pat):\n",
        "        run(f'git add {shlex.quote(p)}', check=False)\n",
        "        added_files.append(p)\n",
        "\n",
        "if not added_files:\n",
        "    print(\"ℹ️  Немає що додавати (файлів не знайдено за списком/патернами).\")\n",
        "\n",
        "# ── 4) Коміт (якщо є staged) ─────────────────────────────────────────────────\n",
        "has_staged = subprocess.run(shlex.split(\"git diff --cached --quiet\")).returncode != 0\n",
        "if has_staged:\n",
        "    ts = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    run(f'git commit -m \"Sync Task20 models & results ({ts})\"', check=False)\n",
        "else:\n",
        "    print(\"ℹ️  Немає staged-змін — коміт пропущено.\")\n",
        "\n",
        "# ── 5) Оновлення віддаленої гілки та rebase ───────────────────────────────────\n",
        "run(f\"git fetch origin {BRANCH}\", check=False)\n",
        "run(f\"git rebase origin/{BRANCH}\", check=False)\n",
        "\n",
        "# ── 6) Пуш із токеном ─────────────────────────────────────────────────────────\n",
        "if \"GH_TOKEN\" not in os.environ or not os.environ[\"GH_TOKEN\"]:\n",
        "    os.environ[\"GH_TOKEN\"] = getpass.getpass(\"GitHub token (приховано): \")\n",
        "\n",
        "push_url = f'https://x-access-token:{os.environ[\"GH_TOKEN\"]}@github.com/{REPO_SLUG}.git'\n",
        "run(f'git push \"{push_url}\" HEAD:{BRANCH}', check=False)\n",
        "\n",
        "# ── 7) Звіт: що є у HEAD ─────────────────────────────────────────────────────\n",
        "res = run('git ls-tree -r HEAD --name-only', check=False, capture=True)\n",
        "head_files = [p for p in res.stdout.splitlines()\n",
        "              if p.startswith((\"out/tables/Task20_\", \"out/tables/_manifest_task20_models.csv\",\n",
        "                               \"models/\", \"app.py\", \"config.yaml\", \"requirements.txt\", \"scripts/\"))]\n",
        "print(\"\\n✅ У HEAD тепер є:\")\n",
        "for p in head_files:\n",
        "    print(\" •\", p)\n"
      ],
      "metadata": {
        "id": "nLUNHlEXo8ow"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}